{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/frederikkeuldahl/Desktop/Fagprojekt/GitHub/HMM\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from HMM_Likelyhood import HMM_log_likelihood,Optimizationloop, InitializeParameters,Accumulated_HHM_LL\n",
    "import LogLikelihoodTorch\n",
    "\n",
    "import HMM_Likelyhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/frederikkeuldahl/Desktop/Fagprojekt/GitHub/GeneralLinearModel\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('GMMsubsetData.pickle','rb') as f:\n",
    "    Xtrain = pickle.load(f) \n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Fit HMM, K = 10, Subjects = 10\n",
    "K=10\n",
    "\n",
    "Pi_MM,Kappa_MM,mu_MM = LogLikelihoodTorch.InitializeFF(Xtrain,90,K)\n",
    "\n",
    "Parameters_MM = [\n",
    "{'params':Pi_MM},\n",
    "{'params':Kappa_MM},\n",
    "{'params':mu_MM},\n",
    "]\n",
    "\n",
    "AdamMM = torch.optim.Adam(Parameters_MM,lr=0.8)\n",
    "AdamMM.zero_grad()\n",
    "LogLikelihoodTorch.Optimizationloop(Xtrain,[Pi_MM,Kappa_MM,mu_MM],lose=LogLikelihoodTorch.log_likelihood,Optimizer=AdamMM,n_iters=2000,K=K)\n",
    "\n",
    "Kappa_HMM,mu_HMM,Tk_HMM,Pinit_HMM = HMM_Likelyhood.InitializeParametersFF(Xtrain,10,90,K)\n",
    "Parameters_HMM= [\n",
    "{'params':Pinit_HMM},\n",
    "{'params':Kappa_HMM},\n",
    "{'params':mu_HMM},\n",
    "{'params':Tk_HMM},\n",
    "]\n",
    "\n",
    "AdamHMM=torch.optim.Adam(Parameters_HMM,lr=1.2)\n",
    "AdamHMM.zero_grad()\n",
    "HMM_Likelyhood.Optimizationloop(Xtrain,[Pinit_HMM,Kappa_HMM,mu_HMM,Tk_HMM],lose=HMM_Likelyhood.Accumulated_HHM_LLHalf,Optimizer=AdamHMM,n=10,n_iters=2000,K=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "B_MM = HMM_Likelyhood.Softmax(LogLikelihoodTorch.log_pdf(Xtrain,mu_MM,Kappa_MM,90).T)\n",
    "B_MM = B_MM/B_MM.sum(0)\n",
    "B_HMM = HMM_Likelyhood.log_pdf(Xtrain,mu_HMM,Kappa_HMM,90).T\n",
    "B_HMM = B_HMM/B_HMM.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "B = np.zeros((10,330*10))\n",
    "\n",
    "for j in range(10):\n",
    "    Prop_HMM_sub1 = torch.zeros((10,330))\n",
    "    Prop_HMM_sub1[:,0] = HMM_Likelyhood.Softmax((HMM_Likelyhood.Softmax(Pinit_HMM[:,j])*B_HMM[:,j*330]))\n",
    "\n",
    "    T1 = HMM_Likelyhood.Softmax(Tk_HMM[j])\n",
    "    for i in range(1,330):\n",
    "        Prop_HMM_sub1[:,i]= torch.nn.Softmax(0)((T1@Prop_HMM_sub1[:,i-1])*B_HMM[:,i])\n",
    "\n",
    "    B[:,j*330:(j+1)*330] = Prop_HMM_sub1.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('HMM_B_K=10.pickle','wb') as f:\n",
    "    pickle.dump([mu_HMM,Kappa_HMM,B], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = B.detach().numpy().T\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(X).to_csv('XHMM_B_K=10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Fit Pytorch fitted Misture Model, K = 10, Subjects = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Setting Up Parameters For Fitting of K Multivariate Watson Distributions\n",
    "\n",
    "K = 10\n",
    "p = 90\n",
    "\n",
    "pi,kappa,mu = LogLikelihoodTorch.InitializeFF(Xtrain,p=p,K=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "learning_rate = 1\n",
    "n_iters = 2000\n",
    "\n",
    "#torch.autograd.set_detect_anomaly(False)\n",
    "Parameters = [\n",
    "    {'params':pi},\n",
    "    {'params':kappa},\n",
    "    {'params':mu}\n",
    "]\n",
    "\n",
    "Adam = torch.optim.Adam(Parameters,lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Optimizing Distribution:\n",
    "Pi_fit,Kappa_fit,mu_fit = LogLikelihoodTorch.Optimizationloop(Xtrain,[pi,kappa,mu],lose=LogLikelihoodTorch.log_likelihood,Optimizer=Adam,n_iters=n_iters,K=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Contraining Parametes and Saving Fitted Model\n",
    "Softmax = torch.nn.Softmax(0)\n",
    "Softplus = torch.nn.Softplus()\n",
    "\n",
    "pi_est = Softmax(Pi_fit)\n",
    "kappa_est = Softplus(Kappa_fit)\n",
    "mu_est = mu /torch.sqrt((mu_fit * mu_fit).sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import LogLikelihoodTorch\n",
    "\n",
    "B = LogLikelihoodTorch.log_pdf(Xtrain,mu_est,kappa_est,p).T\n",
    "\n",
    "B = B/B.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('Torch_B_K=10.pickle','wb') as f:\n",
    "    pickle.dump([pi_est,kappa_est,mu_est,B], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = B.detach().numpy().T\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame(X).to_csv('XTorch_B_K=10.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('Computing')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7186f50bc7e4f6fc7d934fcdcff9c9c1209c61688b8009ca21f1565a7a0186c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}